import os
import re
import json
import time
import random
import string
import logging
import secrets
from typing import Dict, List, Any, Optional, Union
import base64
import io

import requests
from flask import Flask, request, Response, jsonify, stream_with_context

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

app = Flask(__name__)

# æ”¯æŒçš„ç”»å›¾æ¨¡å‹åˆ—è¡¨
SUPPORTED_MODELS = [
    # Fluxæ¨¡å‹
    "black-forest-labs/FLUX.1-dev",
    "black-forest-labs/FLUX.1",
    
    # Kolorsæ¨¡å‹
    "Kwai-Kolors/Kolors",
    
    # Stable Diffusionæ¨¡å‹
    "stabilityai/stable-diffusion-xl-base-1.0",
    "stabilityai/stable-diffusion-2-1-base",
    "runwayml/stable-diffusion-v1-5",
    
    # Midjourneyé£æ ¼æ¨¡å‹
    "prompthero/openjourney",
    
    # åŠ¨æ¼«é£æ ¼æ¨¡å‹
    "Linaqruf/anything-v3.0",
    "hakurei/waifu-diffusion",
    
    # å†™å®é£æ ¼æ¨¡å‹
    "dreamlike-art/dreamlike-photoreal-2.0",
    
    # å…¶ä»–æ¨¡å‹
    "CompVis/stable-diffusion-v1-4",
    "stabilityai/stable-diffusion-2-base"
]

# ç±»å‹å®šä¹‰
class Message:
    def __init__(self, role: str, content: str):
        self.role = role
        self.content = content
    
    def to_dict(self):
        return {
            "role": self.role,
            "content": self.content
        }

class Choice:
    def __init__(self, index: int, message: Message, finish_reason: str):
        self.index = index
        self.message = message
        self.logprobs = None
        self.finish_reason = finish_reason
    
    def to_dict(self):
        return {
            "index": self.index,
            "message": self.message.to_dict(),
            "logprobs": self.logprobs,
            "finish_reason": self.finish_reason
        }

class Usage:
    def __init__(self, prompt_tokens: int, completion_tokens: int, total_tokens: int):
        self.prompt_tokens = prompt_tokens
        self.completion_tokens = completion_tokens
        self.total_tokens = total_tokens
    
    def to_dict(self):
        return {
            "prompt_tokens": self.prompt_tokens,
            "completion_tokens": self.completion_tokens,
            "total_tokens": self.total_tokens
        }

class ResponsePayload:
    def __init__(self, id: int, object: str, created: int, model: str, choices: List[Choice], usage: Usage):
        self.id = id
        self.object = object
        self.created = created
        self.model = model
        self.choices = choices
        self.usage = usage
    
    def to_dict(self):
        return {
            "id": self.id,
            "object": self.object,
            "created": self.created,
            "model": self.model,
            "choices": [choice.to_dict() for choice in self.choices],
            "usage": self.usage.to_dict()
        }

# è¾…åŠ©å‡½æ•°
def get_env(key: str, default: str = "") -> str:
    """è·å–ç¯å¢ƒå˜é‡ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›é»˜è®¤å€¼"""
    return os.environ.get(key, default)

def get_env_bool(key: str, default: bool = False) -> bool:
    """è·å–å¸ƒå°”ç±»å‹ç¯å¢ƒå˜é‡ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›é»˜è®¤å€¼"""
    value = os.environ.get(key, str(default)).lower()
    return value in ("true", "1", "yes", "y", "t")

def get_env_int(key: str, default: int) -> int:
    """è·å–æ•´æ•°ç±»å‹ç¯å¢ƒå˜é‡ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›é»˜è®¤å€¼"""
    try:
        return int(os.environ.get(key, str(default)))
    except ValueError:
        return default

def get_random_api_key() -> str:
    """ä»API_KEYSç¯å¢ƒå˜é‡ä¸­éšæœºé€‰æ‹©ä¸€ä¸ªAPIå¯†é’¥"""
    keys = get_env("API_KEYS", "").split(",")
    if not keys or keys[0] == "":
        raise ValueError("API_KEYS environment variable not set")
    return random.choice(keys)

def contains_chinese(text: str) -> bool:
    """æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦"""
    pattern = re.compile(r'[\u4e00-\u9fff]')
    return bool(pattern.search(text))

def match_resolution(text: str) -> str:
    """ä»æ–‡æœ¬ä¸­åŒ¹é…åˆ†è¾¨ç‡æˆ–å®½é«˜æ¯”"""
    # ç›´æ¥åŒ¹é…å¸¸è§åˆ†è¾¨ç‡æ ¼å¼
    resolution_pattern = re.compile(r'\b(\d+)[xXÃ—*](\d+)\b')
    match = resolution_pattern.search(text)
    if match:
        width, height = match.groups()
        logger.info(f"æ£€æµ‹åˆ°åˆ†è¾¨ç‡: {width}x{height}")
        return f"{width}x{height}"
    
    # é¢„å®šä¹‰çš„åˆ†è¾¨ç‡
    specific_resolutions = [
        "1024x1024", "512x1024", "768x512", "768x1024", "1024x576", "576x1024"
    ]
    
    # æ£€æŸ¥ç‰¹å®šåˆ†è¾¨ç‡å…³é”®è¯
    for resolution in specific_resolutions:
        if re.search(r'\b' + resolution + r'\b', text):
            logger.info(f"åŒ¹é…åˆ°é¢„å®šä¹‰åˆ†è¾¨ç‡: {resolution}")
            return resolution
    
    # å®½é«˜æ¯”æ˜ å°„
    aspect_ratios = {
        "1:1": "1024x1024",
        "1:2": "512x1024", 
        "2:1": "1024x512",
        "3:2": "768x512",
        "2:3": "512x768",
        "3:4": "768x1024",
        "4:3": "1024x768",
        "16:9": "1024x576",
        "9:16": "576x1024"
    }
    
    # æ£€æŸ¥å®½é«˜æ¯”
    for ratio, resolution in aspect_ratios.items():
        if re.search(r'\b' + ratio + r'\b', text):
            logger.info(f"åŒ¹é…åˆ°å®½é«˜æ¯” {ratio}, ä½¿ç”¨åˆ†è¾¨ç‡: {resolution}")
            return resolution
    
    # æ£€æŸ¥å…³é”®è¯
    if re.search(r'\b(square|æ­£æ–¹å½¢)\b', text, re.IGNORECASE):
        return "1024x1024"
    elif re.search(r'\b(landscape|æ¨ªå‘|æ¨ªå±)\b', text, re.IGNORECASE):
        return "1024x768"
    elif re.search(r'\b(portrait|çºµå‘|ç«–å±)\b', text, re.IGNORECASE):
        return "768x1024"
    elif re.search(r'\b(wide|å®½å±)\b', text, re.IGNORECASE):
        return "1024x576"
    
    logger.info("æœªæ£€æµ‹åˆ°ç‰¹å®šåˆ†è¾¨ç‡ï¼Œä½¿ç”¨é»˜è®¤å€¼: 1024x1024")
    return "1024x1024"  # é»˜è®¤åˆ†è¾¨ç‡

def moderate_check(text: str) -> bool:
    """æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŒ…å«è¢«ç¦æ­¢çš„å…³é”®è¯"""
    banned_words = get_env("BANNED_KEYWORDS", "").split(",")
    text_lower = text.lower()
    
    for word in banned_words:
        if word and word.strip() and word.strip().lower() in text_lower:
            logger.info(f"æ£€æµ‹åˆ°ç¦æ­¢å…³é”®è¯: {word}")
            return True
    
    return False

def generate_random_slug(length: int = 3) -> str:
    """ç”ŸæˆéšæœºçŸ­é“¾æ¥æ ‡è¯†"""
    chars = string.ascii_letters + string.digits
    return ''.join(random.choice(chars) for _ in range(length))

def generate_short_url(long_url: str) -> str:
    """ç”ŸæˆçŸ­é“¾æ¥"""
    # æ£€æŸ¥æ˜¯å¦å¯ç”¨çŸ­é“¾æ¥æœåŠ¡
    if not get_env_bool("USE_SHORTLINK", False):
        return long_url
    
    if len(long_url) < 30:
        return long_url
    
    base_url = get_env("SHORTLINK_BASE_URL")
    api_key = get_env("SHORTLINK_API_KEY")
    
    if not base_url or not api_key:
        return long_url
    
    slug = generate_random_slug()
    api_url = f"{base_url}/api/link/create"
    
    try:
        response = requests.post(
            api_url,
            json={"url": long_url, "slug": slug},
            headers={
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            },
            timeout=5
        )
        
        if response.status_code in (200, 201):
            return f"{base_url}{slug}"
        
        logger.error(f"çŸ­é“¾æ¥APIé”™è¯¯å“åº”: {response.text}")
    except Exception as e:
        logger.error(f"ç”ŸæˆçŸ­é“¾æ¥å¤±è´¥: {e}")
    
    return long_url

def upload_to_lsky_pro(image_url: str) -> Optional[str]:
    """ä¸Šä¼ å›¾ç‰‡åˆ°è“ç©ºå›¾åºŠ"""
    # æ£€æŸ¥æ˜¯å¦å¯ç”¨è“ç©ºå›¾åºŠ
    if not get_env_bool("USE_LSKY_PRO", False):
        return None
    
    lsky_url = get_env("LSKY_PRO_URL")
    lsky_token = get_env("LSKY_PRO_TOKEN")
    
    if not lsky_url or not lsky_token:
        logger.error("è“ç©ºå›¾åºŠé…ç½®ä¸å®Œæ•´ï¼Œè¯·æ£€æŸ¥LSKY_PRO_URLå’ŒLSKY_PRO_TOKENç¯å¢ƒå˜é‡")
        return None
    
    try:
        # ä¸‹è½½åŸå§‹å›¾ç‰‡
        logger.info(f"ä» {image_url} ä¸‹è½½å›¾ç‰‡")
        image_response = requests.get(image_url, timeout=10)
        if image_response.status_code != 200:
            logger.error(f"ä¸‹è½½å›¾ç‰‡å¤±è´¥: {image_response.status_code}")
            return None
        
        # å‡†å¤‡ä¸Šä¼ åˆ°è“ç©ºå›¾åºŠ
        upload_url = f"{lsky_url.rstrip('/')}/api/v1/upload"
        
        # ä½¿ç”¨multipart/form-dataä¸Šä¼ 
        files = {
            'file': ('image.png', image_response.content, 'image/png')
        }
        
        headers = {
            'Authorization': f'Bearer {lsky_token}'
        }
        
        logger.info(f"ä¸Šä¼ å›¾ç‰‡åˆ°è“ç©ºå›¾åºŠ: {upload_url}")
        upload_response = requests.post(
            upload_url,
            files=files,
            headers=headers,
            timeout=30
        )
        
        if upload_response.status_code != 200:
            logger.error(f"ä¸Šä¼ åˆ°è“ç©ºå›¾åºŠå¤±è´¥: {upload_response.status_code}, {upload_response.text}")
            return None
        
        # è§£æå“åº”
        try:
            result = upload_response.json()
            if result.get("status") and "data" in result and "links" in result["data"]:
                lsky_url = result["data"]["links"].get("url")
                if lsky_url:
                    logger.info(f"ä¸Šä¼ åˆ°è“ç©ºå›¾åºŠæˆåŠŸ: {lsky_url}")
                    return lsky_url
            
            logger.error(f"è§£æè“ç©ºå›¾åºŠå“åº”å¤±è´¥: {result}")
        except Exception as e:
            logger.error(f"è§£æè“ç©ºå›¾åºŠå“åº”å¤±è´¥: {e}")
        
    except Exception as e:
        logger.error(f"ä¸Šä¼ åˆ°è“ç©ºå›¾åºŠå¤±è´¥: {e}")
    
    return None

def generate_image_prompt(api_key: str, text: str) -> str:
    """ä½¿ç”¨LLMç”Ÿæˆå›¾åƒæç¤º"""
    image_prompt_model = get_env("IMAGE_PROMPT_MODEL", "Qwen/Qwen2.5-7B-Instruct")
    llm_api_url = get_env("LLM_API_URL", "http://localhost:3000/v1/chat/completions")
    
    messages = [
        {
            "role": "system",
            "content": "ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯ç²¾æ¹›ã€å–„äºè§‚å¯Ÿã€å¯Œæœ‰åˆ›é€ åŠ›å’Œæƒ³è±¡åŠ›ã€æ“…é•¿ä½¿ç”¨ç²¾å‡†è¯­è¨€æè¿°ç”»é¢çš„è‰ºæœ¯å®¶ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„ä½œç”»è¯·æ±‚ï¼ˆå¯èƒ½æ˜¯ä¸€ç»„åŒ…å«ç»˜ç”»è¦æ±‚çš„ä¸Šä¸‹æ–‡ï¼Œè·³è¿‡å…¶ä¸­çš„éç»˜ç”»å†…å®¹ï¼‰ï¼Œæ‰©å……ä¸ºä¸€æ®µå…·ä½“çš„ç”»é¢æè¿°ï¼Œ100 wordsä»¥å†…ã€‚å¯ä»¥åŒ…æ‹¬ç”»é¢å†…å®¹ã€é£æ ¼ã€æŠ€æ³•ç­‰ï¼Œä½¿ç”¨è‹±æ–‡å›å¤."
        },
        {
            "role": "user",
            "content": text
        }
    ]
    
    try:
        response = requests.post(
            llm_api_url,
            json={
                "model": image_prompt_model,
                "messages": messages
            },
            headers={
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            }
        )
        
        if response.status_code == 200:
            result = response.json()
            return result["choices"][0]["message"]["content"]
    except Exception as e:
        logger.error(f"ç”Ÿæˆå›¾åƒæç¤ºå¤±è´¥: {e}")
    
    return text

def generate_image_stream(unique_id: int, current_timestamp: int, model: str, prompt: str, 
                         new_url: str, new_request_body: Dict, headers: Dict):
    """ç”Ÿæˆå›¾åƒæµå¼å“åº”"""
    # æç¤ºä¿¡æ¯
    prompt_payload = {
        "id": unique_id,
        "object": "chat.completion.chunk",
        "created": current_timestamp,
        "model": model,
        "choices": [
            {
                "index": 0,
                "delta": {
                    "content": f"```\n{{\n  \"prompt\":\"{prompt}\"\n}}\n```\n"
                }
            }
        ],
        "finish_reason": None
    }
    yield f"data: {json.dumps(prompt_payload)}\n\n"
    
    # ç­‰å¾…ä¸€å°æ®µæ—¶é—´ï¼Œç¡®ä¿å®¢æˆ·ç«¯æ”¶åˆ°æç¤ºä¿¡æ¯
    time.sleep(0.5)
    
    # ä»»åŠ¡è¿›è¡Œä¸­
    task_payload = {
        "id": unique_id,
        "object": "chat.completion.chunk",
        "created": current_timestamp,
        "model": model,
        "choices": [
            {
                "index": 0,
                "delta": {
                    "content": "> ç”Ÿæˆä¸­"
                }
            }
        ],
        "finish_reason": None
    }
    yield f"data: {json.dumps(task_payload)}\n\n"
    
    # ç­‰å¾…ä¸€å°æ®µæ—¶é—´ï¼Œç¡®ä¿å®¢æˆ·ç«¯æ”¶åˆ°è¿›è¡Œä¸­ä¿¡æ¯
    time.sleep(0.5)

    # è¯·æ±‚å·²æäº¤
    submitted_payload = {
        "id": unique_id,
        "object": "chat.completion.chunk",
        "created": current_timestamp,
        "model": model,
        "choices": [
            {
                "index": 0,
                "delta": {
                    "content": "\nç”Ÿæˆä¸­âœ…"
                }
            }
        ],
        "finish_reason": None
    }
    yield f"data: {json.dumps(submitted_payload)}\n\n"

    # ç­‰å¾…ä¸€å°æ®µæ—¶é—´ï¼Œç¡®ä¿å®¢æˆ·ç«¯æ”¶åˆ°æäº¤æˆåŠŸä¿¡æ¯
    time.sleep(0.5)
    
    # è°ƒç”¨å›¾åƒç”ŸæˆAPI
    try:
        logger.info(f"è°ƒç”¨å›¾åƒç”ŸæˆAPI: {new_url}")
        logger.info(f"è¯·æ±‚å¤´: {headers}")
        logger.info(f"è¯·æ±‚ä½“: {new_request_body}")
        
        response = requests.post(
            new_url,
            json=new_request_body,
            headers=headers
        )
        
        logger.info(f"APIå“åº”çŠ¶æ€ç : {response.status_code}")
        logger.info(f"APIå“åº”å†…å®¹: {response.text[:200]}...")
        
        # ç¡®ä¿å“åº”æ˜¯JSONæ ¼å¼
        try:
            response_body = response.json()
        except json.JSONDecodeError as e:
            logger.error(f"è§£æAPIå“åº”å¤±è´¥: {e}, å“åº”å†…å®¹: {response.text}")
            response_body = {"message": f"è§£æAPIå“åº”å¤±è´¥: {response.text[:100]}..."}
        
        # æ£€æŸ¥å“åº”ä¸­æ˜¯å¦åŒ…å«å›¾åƒURL
        if isinstance(response_body, dict) and "images" in response_body and response_body["images"]:
            # ç¡®ä¿imagesæ˜¯åˆ—è¡¨ä¸”åŒ…å«å­—å…¸å…ƒç´ 
            if isinstance(response_body["images"], list) and len(response_body["images"]) > 0:
                image_item = response_body["images"][0]
                if isinstance(image_item, dict) and "url" in image_item:
                    image_url = image_item["url"]
                    logger.info(f"æ¥æ”¶åˆ°çš„ imageURL: {image_url}")
                    
                    # ç”ŸæˆçŸ­é“¾æ¥
                    short_url = generate_short_url(image_url)
                    
                    # ä¸Šä¼ åˆ°è“ç©ºå›¾åºŠ
                    lsky_url = upload_to_lsky_pro(image_url)
                    
                    # æ„å»ºå“åº”æ–‡æœ¬
                    # ç¡®ä¿promptä¸åŒ…å«æ¢è¡Œç¬¦
                    safe_prompt = prompt.replace("\n", " ")
                    
                    if lsky_url:
                        task_text = f"âœ…\nä¸‹è½½é“¾æ¥(é“¾æ¥æœ‰æ—¶æ•ˆæ€§ï¼ŒåŠæ—¶ä¸‹è½½ä¿å­˜)ï¼š{short_url}\n\nè“ç©ºå›¾åºŠé“¾æ¥(æ°¸ä¹…æœ‰æ•ˆ)ï¼š{lsky_url}\n\n![image1|{safe_prompt}]({lsky_url})"
                    else:
                        task_text = f"âœ…\nä¸‹è½½é“¾æ¥(é“¾æ¥æœ‰æ—¶æ•ˆæ€§ï¼ŒåŠæ—¶ä¸‹è½½ä¿å­˜)ï¼š{short_url}\n\n![image1|{safe_prompt}]({short_url})"
                else:
                    logger.error(f"å›¾åƒé¡¹æ ¼å¼é”™è¯¯: {image_item}")
                    task_text = f"âŒ\n\n\`\`\`\n{{\n  \"message\":\"å›¾åƒæ ¼å¼é”™è¯¯\"\n}}\n\`\`\`"
            else:
                logger.error(f"å›¾åƒåˆ—è¡¨æ ¼å¼é”™è¯¯: {response_body['images']}")
                task_text = f"âŒ\n\n\`\`\`\n{{\n  \"message\":\"å›¾åƒåˆ—è¡¨æ ¼å¼é”™è¯¯\"\n}}\n\`\`\`"
        else:
            error_msg = "æœªçŸ¥é”™è¯¯"
            if isinstance(response_body, dict) and "message" in response_body:
                error_msg = str(response_body["message"])
            task_text = f"âŒ\n\n\`\`\`\n{{\n  \"message\":\"{error_msg}\"\n}}\n\`\`\`"
            logger.error(f"ç”»å›¾å¤±è´¥ï¼š{response_body}")
        
        task_payload["choices"][0]["delta"]["content"] = task_text
        yield f"data: {json.dumps(task_payload)}\n\n"
    except Exception as e:
        logger.error(f"ç”Ÿæˆå›¾åƒå¤±è´¥: {str(e)}")
        task_text = f"âŒ\n\n\`\`\`\n{{\n  \"message\":\"æœåŠ¡å™¨é”™è¯¯: {str(e)}\"\n}}\n\`\`\`"
        task_payload["choices"][0]["delta"]["content"] = task_text
        yield f"data: {json.dumps(task_payload)}\n\n"
    
    yield "data: [DONE]\n\n"

def send_response(body: Dict, response_text: str) -> Dict:
    """æ„å»ºAPIå“åº”"""
    unique_id = int(time.time() * 1000)
    current_timestamp = int(time.time())
    
    return {
        "id": unique_id,
        "object": "chat.completion",
        "created": current_timestamp,
        "model": body["model"],
        "choices": [
            {
                "index": 0,
                "message": {
                    "role": "assistant",
                    "content": response_text
                },
                "logprobs": None,
                "finish_reason": "stop"
            }
        ],
        "usage": {
            "prompt_tokens": len(body["messages"][-1]["content"]),
            "completion_tokens": len(response_text),
            "total_tokens": len(body["messages"][-1]["content"]) + len(response_text)
        }
    }

def verify_api_key(request_auth: str) -> bool:
    """éªŒè¯APIå¯†é’¥"""
    service_api_key = get_env("API_KEY", "")
    
    # å¦‚æœæœªè®¾ç½®API_KEYç¯å¢ƒå˜é‡ï¼Œåˆ™ä¸è¿›è¡ŒéªŒè¯
    if not service_api_key:
        return True
    
    # æ£€æŸ¥è¯·æ±‚å¤´ä¸­çš„Authorization
    if not request_auth:
        return False
    
    # æå–Bearer token
    parts = request_auth.split()
    if len(parts) != 2 or parts[0].lower() != "bearer":
        return False
    
    # éªŒè¯token
    return parts[1] == service_api_key

def extract_image_count(text: str) -> tuple[str, int]:
    """ä»æ–‡æœ¬ä¸­æå–å›¾ç‰‡æ•°é‡ï¼Œå¹¶è¿”å›å¤„ç†åçš„æ–‡æœ¬å’Œå›¾ç‰‡æ•°é‡"""
    # é»˜è®¤å›¾ç‰‡æ•°é‡
    default_count = get_env_int("MAX_IMAGES_PER_REQUEST", 4)
    
    # æŸ¥æ‰¾ pic:number æ¨¡å¼
    pattern = re.compile(r'\bpic:(\d+)\b')
    match = pattern.search(text)
    
    if not match:
        return text, 1  # é»˜è®¤ç”Ÿæˆ1å¼ å›¾ç‰‡
    
    # æå–æ•°é‡
    count = int(match.group(1))
    # é™åˆ¶æœ€å¤§æ•°é‡
    count = min(count, default_count)
    
    # ä»æ–‡æœ¬ä¸­ç§»é™¤ pic:number
    cleaned_text = pattern.sub('', text).strip()
    
    logger.info(f"æ£€æµ‹åˆ°å›¾ç‰‡æ•°é‡è®¾ç½®: {count}å¼ ")
    return cleaned_text, count

# APIè·¯ç”±
@app.route("/v1/models", methods=["GET"])
def list_models():
    """åˆ—å‡ºæ”¯æŒçš„æ¨¡å‹"""
    # éªŒè¯APIå¯†é’¥
    if not verify_api_key(request.headers.get("Authorization", "")):
        return jsonify({"error": "Unauthorized: Invalid API key"}), 401
    
    models_data = {
        "object": "list",
        "data": [{"id": model, "object": "model"} for model in SUPPORTED_MODELS]
    }
    return jsonify(models_data)

@app.route("/v1/chat/completions", methods=["POST"])
def handle_request():
    """å¤„ç†å›¾åƒç”Ÿæˆè¯·æ±‚"""
    try:
        # éªŒè¯APIå¯†é’¥
        if not verify_api_key(request.headers.get("Authorization", "")):
            return jsonify({"error": "Unauthorized: Invalid API key"}), 401
        
        body = request.json
        
        # éªŒè¯è¯·æ±‚
        if not body or "model" not in body or "messages" not in body or not body["messages"]:
            return jsonify({"error": "Bad Request: Missing required fields"}), 400
        
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦ä¸‹æ¶
        if "janus" in body["model"].lower():
            return jsonify({"error": f"è¯¥æ¨¡å‹å·²ä¸‹æ¶: {body['model']}"}), 410
        
        # æ„å»ºå®Œæ•´ä¸Šä¸‹æ–‡
        full_context = ""
        for message in body["messages"]:
            if message["role"] != "assistant":
                full_context += message["content"] + "\n\n"
        context = full_context.strip()
        
        # æå–å›¾ç‰‡æ•°é‡
        context, image_count = extract_image_count(context)
        
        # å†…å®¹å®¡æ ¸
        if moderate_check(context):
            nsfw_response = "Warning: Prohibited Content Detected! ğŸš«\n\nYour request contains banned keywords. Please check the content and try again.\n\n-----------------------\n\nè­¦å‘Šï¼šè¯·æ±‚åŒ…å«è¢«ç¦æ­¢çš„å…³é”®è¯ï¼Œè¯·æ£€æŸ¥åé‡è¯•ï¼âš ï¸"
            
            # æµå¼å“åº”
            if body.get("stream", False):
                def generate():
                    unique_id = int(time.time() * 1000)
                    current_timestamp = int(time.time())
                    
                    # åˆå§‹å“åº”
                    initial_payload = {
                        "id": unique_id,
                        "object": "chat.completion.chunk",
                        "created": current_timestamp,
                        "model": body["model"],
                        "choices": [
                            {
                                "index": 0,
                                "delta": {"role": "assistant"},
                                "finish_reason": None,
                                "logprobs": None
                            }
                        ],
                        "system_fingerprint": "fp_default"
                    }
                    yield f"data: {json.dumps(initial_payload)}\n\n"
                    
                    # åˆ†å—å‘é€NSFWè­¦å‘Š
                    for chunk in nsfw_response:
                        payload = {
                            "id": unique_id,
                            "object": "chat.completion.chunk",
                            "created": current_timestamp,
                            "model": body["model"],
                            "choices": [
                                {
                                    "index": 0,
                                    "delta": {"content": chunk},
                                    "finish_reason": None,
                                    "logprobs": None
                                }
                            ],
                            "system_fingerprint": "fp_default"
                        }
                        yield f"data: {json.dumps(payload)}\n\n"
                    
                    # ç»“æŸå“åº”
                    end_payload = {
                        "id": unique_id,
                        "object": "chat.completion.chunk",
                        "created": current_timestamp,
                        "model": body["model"],
                        "choices": [
                            {
                                "index": 0,
                                "delta": {},
                                "finish_reason": "stop",
                                "logprobs": None
                            }
                        ],
                        "system_fingerprint": "fp_default"
                    }
                    yield f"data: {json.dumps(end_payload)}\n\n"
                    yield "data: [DONE]\n\n"
                
                return Response(stream_with_context(generate()), content_type="text/event-stream")
            
            # éæµå¼å“åº”
            else:
                response_payload = {
                    "id": int(time.time() * 1000),
                    "object": "chat.completion",
                    "created": int(time.time()),
                    "model": body["model"],
                    "choices": [
                        {
                            "index": 0,
                            "message": {
                                "role": "assistant",
                                "content": nsfw_response
                            },
                            "logprobs": None,
                            "finish_reason": "stop"
                        }
                    ],
                    "usage": {
                        "prompt_tokens": len(context),
                        "completion_tokens": len(nsfw_response),
                        "total_tokens": len(context) + len(nsfw_response)
                    }
                }
                return jsonify(response_payload)
        
        # è·å–å¤–éƒ¨APIå¯†é’¥åˆ—è¡¨
        try:
            api_keys = get_env("API_KEYS", "").split(",")
            if not api_keys or api_keys[0] == "":
                raise ValueError("API_KEYS environment variable not set")
            
            # ç¡®ä¿æœ‰å¯ç”¨çš„APIå¯†é’¥
            available_keys = len(api_keys)
            max_images = get_env_int("MAX_IMAGES_PER_REQUEST", 4)
            
            # ç”¨æˆ·è¯·æ±‚çš„å›¾ç‰‡æ•°é‡ä¸èƒ½è¶…è¿‡ç¯å¢ƒå˜é‡é™åˆ¶
            requested_count = min(image_count, max_images)
            
            # æœ€ç»ˆç”Ÿæˆçš„å›¾ç‰‡æ•°é‡ä¸ºç”¨æˆ·è¯·æ±‚çš„æ•°é‡ï¼ˆå—ç¯å¢ƒå˜é‡é™åˆ¶ï¼‰
            final_count = requested_count
            
            logger.info(f"ç¯å¢ƒå˜é‡é™åˆ¶: {max_images}å¼ , ç”¨æˆ·è¯·æ±‚: {image_count}å¼ , å¯ç”¨APIå¯†é’¥: {available_keys}ä¸ª, æœ€ç»ˆç”Ÿæˆ: {final_count}å¼ ")
            
            # é€‰æ‹©APIå¯†é’¥ï¼Œå…è®¸é‡å¤ä½¿ç”¨ä»¥å®ç°è´Ÿè½½å‡è¡¡
            selected_keys = []
            for i in range(final_count):
                # å¾ªç¯ä½¿ç”¨å¯ç”¨çš„APIå¯†é’¥
                key_index = i % available_keys
                selected_keys.append(api_keys[key_index])
            
            logger.info(f"å·²é€‰æ‹© {len(selected_keys)} ä¸ªAPIå¯†é’¥ç”¨äºå›¾åƒç”Ÿæˆï¼ˆå¯èƒ½åŒ…å«é‡å¤ä½¿ç”¨çš„å¯†é’¥ï¼‰")
        except ValueError as e:
            logger.error(f"è·å–å¤–éƒ¨APIå¯†é’¥å¤±è´¥: {e}")
            return jsonify({"error": "æœªé…ç½®å¤–éƒ¨APIå¯†é’¥ï¼Œè¯·è®¾ç½®API_KEYSç¯å¢ƒå˜é‡"}), 500
        
        # ç”Ÿæˆå›¾åƒæç¤º
        prompt = generate_image_prompt(selected_keys[0], context)
        # ç¡®ä¿promptä¸åŒ…å«æ¢è¡Œç¬¦ï¼Œé¿å…Markdownæ ¼å¼é—®é¢˜
        safe_prompt = prompt.replace("\n", " ")
        
        image_size = match_resolution(context)  # ä»åŸå§‹ä¸Šä¸‹æ–‡ä¸­åŒ¹é…åˆ†è¾¨ç‡ï¼Œè€Œä¸æ˜¯ä»ç”Ÿæˆçš„æç¤ºä¸­
        logger.info(f"ç”¨æˆ·è¯·æ±‚çš„å›¾åƒå°ºå¯¸: {image_size}")
        
        # é…ç½®API URL
        api_base_url = get_env("API_BASE_URL", "https://api.siliconflow.cn")
        
        # å‡†å¤‡å¤šä¸ªè¯·æ±‚é…ç½®
        request_configs = []
        for i in range(final_count):
            # æ ¹æ®æ¨¡å‹é€‰æ‹©åˆé€‚çš„APIç«¯ç‚¹
            if body["model"] == "Kwai-Kolors/Kolors":
                new_url = f"{api_base_url}/v1/images/generations"
                new_request_body = {
                    "model": body["model"],
                    "prompt": prompt,
                    "image_size": image_size,
                    "batch_size": 1,
                    "num_inference_steps": 20,
                    "guidance_scale": 7.5
                }
            elif "flux" in body["model"].lower():
                new_url = f"{api_base_url}/v1/image/generations"
                new_request_body = {
                    "model": body["model"],
                    "prompt": prompt,
                    "image_size": image_size,
                    "num_inference_steps": 20,
                    "prompt_enhancement": True
                }
            else:
                new_url = f"{api_base_url}/v1/{body['model']}/text-to-image"
                new_request_body = {
                    "prompt": prompt,
                    "image_size": image_size,
                    "num_inference_steps": 20
                }
            
            # è®¾ç½®å¤–éƒ¨APIè¯·æ±‚å¤´ - ä½¿ç”¨API_KEYSä¸­çš„å¯†é’¥ï¼Œè€Œä¸æ˜¯æœåŠ¡çš„API_KEY
            headers = {
                "accept": "application/json",
                "content-type": "application/json",
                "Authorization": f"Bearer {selected_keys[i]}"
            }
            
            request_configs.append({
                "url": new_url,
                "body": new_request_body,
                "headers": headers,
                "index": i
            })
        
        logger.info(f"å‡†å¤‡å‘é€ {len(request_configs)} ä¸ªå¹¶å‘è¯·æ±‚")
        
        unique_id = int(time.time() * 1000)
        current_timestamp = int(time.time())
        
        # æµå¼å“åº”
        if body.get("stream", False):
            def generate():
                # åˆå§‹å“åº” - è§’è‰²ä¿¡æ¯
                initial_payload = {
                    "id": unique_id,
                    "object": "chat.completion.chunk",
                    "created": current_timestamp,
                    "model": body["model"],
                    "choices": [
                        {
                            "index": 0,
                            "delta": {"role": "assistant"},
                            "finish_reason": None,
                            "logprobs": None
                        }
                    ],
                    "system_fingerprint": "fp_default"
                }
                yield f"data: {json.dumps(initial_payload)}\n\n"
                
                # ç¡®ä¿ç«‹å³åˆ·æ–°
                time.sleep(0.1)
                
                # æç¤ºä¿¡æ¯
                prompt_payload = {
                    "id": unique_id,
                    "object": "chat.completion.chunk",
                    "created": current_timestamp,
                    "model": body["model"],
                    "choices": [
                        {
                            "index": 0,
                            "delta": {
                                "content": f"```\n{{\n  \"prompt\":\"{safe_prompt}\",\n  \"count\":{final_count}\n}}\n```\n"
                            }
                        }
                    ],
                    "finish_reason": None
                }
                yield f"data: {json.dumps(prompt_payload)}\n\n"
                
                # ç­‰å¾…ä¸€å°æ®µæ—¶é—´ï¼Œç¡®ä¿å®¢æˆ·ç«¯æ”¶åˆ°æç¤ºä¿¡æ¯
                time.sleep(0.5)
                
                # ä»»åŠ¡è¿›è¡Œä¸­
                task_payload = {
                    "id": unique_id,
                    "object": "chat.completion.chunk",
                    "created": current_timestamp,
                    "model": body["model"],
                    "choices": [
                        {
                            "index": 0,
                            "delta": {
                                "content": f"> æ­£åœ¨ç”Ÿæˆ {final_count} å¼ å›¾ç‰‡..."
                            }
                        }
                    ],
                    "finish_reason": None
                }
                yield f"data: {json.dumps(task_payload)}\n\n"
                
                # ç­‰å¾…ä¸€å°æ®µæ—¶é—´ï¼Œç¡®ä¿å®¢æˆ·ç«¯æ”¶åˆ°è¿›è¡Œä¸­ä¿¡æ¯
                time.sleep(0.5)
                
                # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘è¯·æ±‚
                import concurrent.futures
                
                def make_request(config):
                    try:
                        logger.info(f"å‘é€è¯·æ±‚ #{config['index']+1} åˆ°: {config['url']}")
                        logger.info(f"ä½¿ç”¨APIå¯†é’¥: {config['headers']['Authorization'][:15]}...")
                        response = requests.post(
                            config['url'], 
                            json=config['body'], 
                            headers=config['headers'],
                            timeout=60  # å¢åŠ è¶…æ—¶æ—¶é—´
                        )
                        return {
                            "index": config['index'],
                            "status_code": response.status_code,
                            "response": response.json() if response.status_code == 200 else {"error": response.text}
                        }
                    except Exception as e:
                        logger.error(f"è¯·æ±‚ #{config['index']+1} å¤±è´¥: {str(e)}")
                        return {
                            "index": config['index'],
                            "status_code": 500,
                            "response": {"error": str(e)}
                        }
                
                # åˆ›å»ºçº¿ç¨‹æ± 
                with concurrent.futures.ThreadPoolExecutor(max_workers=final_count) as executor:
                    # æäº¤æ‰€æœ‰è¯·æ±‚
                    future_to_config = {executor.submit(make_request, config): config for config in request_configs}
                    
                    # å¤„ç†å®Œæˆçš„è¯·æ±‚
                    for i, future in enumerate(concurrent.futures.as_completed(future_to_config)):
                        config = future_to_config[future]
                        try:
                            result = future.result()
                            logger.info(f"è¯·æ±‚ #{result['index']+1} å®Œæˆï¼ŒçŠ¶æ€ç : {result['status_code']}")
                            
                            # å¤„ç†å“åº”
                            if result['status_code'] == 200:
                                response_body = result['response']
                                
                                # æ£€æŸ¥å“åº”ä¸­æ˜¯å¦åŒ…å«å›¾åƒURL
                                if isinstance(response_body, dict) and "images" in response_body and response_body["images"]:
                                    # ç¡®ä¿imagesæ˜¯åˆ—è¡¨ä¸”åŒ…å«å­—å…¸å…ƒç´ 
                                    if isinstance(response_body["images"], list) and len(response_body["images"]) > 0:
                                        image_item = response_body["images"][0]
                                        if isinstance(image_item, dict) and "url" in image_item:
                                            image_url = image_item["url"]
                                            logger.info(f"è¯·æ±‚ #{result['index']+1} æ¥æ”¶åˆ°çš„ imageURL: {image_url}")
                                            
                                            # ç”ŸæˆçŸ­é“¾æ¥
                                            short_url = generate_short_url(image_url)
                                            
                                            # ä¸Šä¼ åˆ°è“ç©ºå›¾åºŠ
                                            lsky_url = upload_to_lsky_pro(image_url)
                                            
                                            # æ„å»ºå“åº”æ–‡æœ¬
                                            if lsky_url:
                                                image_text = f"\n\nå›¾ç‰‡ #{result['index']+1}/{final_count} ç”Ÿæˆå®Œæˆ âœ…\nä¸‹è½½é“¾æ¥(é“¾æ¥æœ‰æ—¶æ•ˆæ€§ï¼ŒåŠæ—¶ä¸‹è½½ä¿å­˜)ï¼š{short_url}\n\nè“ç©ºå›¾åºŠé“¾æ¥(æ°¸ä¹…æœ‰æ•ˆ)ï¼š{lsky_url}\n\n![image{result['index']+1}|{safe_prompt}]({lsky_url})"
                                            else:
                                                image_text = f"\n\nå›¾ç‰‡ #{result['index']+1}/{final_count} ç”Ÿæˆå®Œæˆ âœ…\nä¸‹è½½é“¾æ¥(é“¾æ¥æœ‰æ—¶æ•ˆæ€§ï¼ŒåŠæ—¶ä¸‹è½½ä¿å­˜)ï¼š{short_url}\n\n![image{result['index']+1}|{safe_prompt}]({short_url})"
                                            
                                            # å‘é€å›¾ç‰‡ç»“æœ
                                            image_payload = {
                                                "id": unique_id,
                                                "object": "chat.completion.chunk",
                                                "created": current_timestamp,
                                                "model": body["model"],
                                                "choices": [
                                                    {
                                                        "index": 0,
                                                        "delta": {
                                                            "content": image_text
                                                        }
                                                    }
                                                ],
                                                "finish_reason": None
                                            }
                                            yield f"data: {json.dumps(image_payload)}\n\n"
                                        else:
                                            logger.error(f"è¯·æ±‚ #{result['index']+1} å›¾åƒé¡¹æ ¼å¼é”™è¯¯: {image_item}")
                                            error_text = f"\n\nå›¾ç‰‡ #{result['index']+1}/{final_count} ç”Ÿæˆå¤±è´¥ âŒ - å›¾åƒæ ¼å¼é”™è¯¯"
                                            error_payload = {
                                                "id": unique_id,
                                                "object": "chat.completion.chunk",
                                                "created": current_timestamp,
                                                "model": body["model"],
                                                "choices": [
                                                    {
                                                        "index": 0,
                                                        "delta": {
                                                            "content": error_text
                                                        }
                                                    }
                                                ],
                                                "finish_reason": None
                                            }
                                            yield f"data: {json.dumps(error_payload)}\n\n"
                                    else:
                                        logger.error(f"è¯·æ±‚ #{result['index']+1} å›¾åƒåˆ—è¡¨æ ¼å¼é”™è¯¯: {response_body['images']}")
                                        error_text = f"\n\nå›¾ç‰‡ #{result['index']+1}/{final_count} ç”Ÿæˆå¤±è´¥ âŒ - å›¾åƒåˆ—è¡¨æ ¼å¼é”™è¯¯"
                                        error_payload = {
                                            "id": unique_id,
                                            "object": "chat.completion.chunk",
                                            "created": current_timestamp,
                                            "model": body["model"],
                                            "choices": [
                                                {
                                                    "index": 0,
                                                    "delta": {
                                                        "content": error_text
                                                    }
                                                }
                                            ],
                                            "finish_reason": None
                                        }
                                        yield f"data: {json.dumps(error_payload)}\n\n"
                                else:
                                    error_msg = "æœªçŸ¥é”™è¯¯"
                                    if isinstance(response_body, dict) and "message" in response_body:
                                        error_msg = str(response_body["message"])
                                    logger.error(f"è¯·æ±‚ #{result['index']+1} ç”»å›¾å¤±è´¥ï¼š{response_body}")
                                    error_text = f"\n\nå›¾ç‰‡ #{result['index']+1}/{final_count} ç”Ÿæˆå¤±è´¥ âŒ - {error_msg}"
                                    error_payload = {
                                        "id": unique_id,
                                        "object": "chat.completion.chunk",
                                        "created": current_timestamp,
                                        "model": body["model"],
                                        "choices": [
                                            {
                                                "index": 0,
                                                "delta": {
                                                    "content": error_text
                                                }
                                            }
                                        ],
                                        "finish_reason": None
                                    }
                                    yield f"data: {json.dumps(error_payload)}\n\n"
                            else:
                                logger.error(f"è¯·æ±‚ #{result['index']+1} è¿”å›é”™è¯¯çŠ¶æ€ç : {result['status_code']}")
                                error_text = f"\n\nå›¾ç‰‡ #{result['index']+1}/{final_count} ç”Ÿæˆå¤±è´¥ âŒ - æœåŠ¡å™¨è¿”å›é”™è¯¯: {result['status_code']}"
                                error_payload = {
                                    "id": unique_id,
                                    "object": "chat.completion.chunk",
                                    "created": current_timestamp,
                                    "model": body["model"],
                                    "choices": [
                                        {
                                            "index": 0,
                                            "delta": {
                                                "content": error_text
                                            }
                                        }
                                    ],
                                    "finish_reason": None
                                }
                                yield f"data: {json.dumps(error_payload)}\n\n"
                        except Exception as e:
                            logger.error(f"å¤„ç†è¯·æ±‚ #{config['index']+1} ç»“æœæ—¶å‡ºé”™: {str(e)}")
                            error_text = f"\n\nå›¾ç‰‡ #{config['index']+1}/{final_count} ç”Ÿæˆå¤±è´¥ âŒ - å¤„ç†ç»“æœæ—¶å‡ºé”™: {str(e)}"
                            error_payload = {
                                "id": unique_id,
                                "object": "chat.completion.chunk",
                                "created": current_timestamp,
                                "model": body["model"],
                                "choices": [
                                    {
                                        "index": 0,
                                        "delta": {
                                            "content": error_text
                                        }
                                    }
                                ],
                                "finish_reason": None
                            }
                            yield f"data: {json.dumps(error_payload)}\n\n"
                
                # æ‰€æœ‰å›¾ç‰‡å¤„ç†å®Œæˆ
                completion_payload = {
                    "id": unique_id,
                    "object": "chat.completion.chunk",
                    "created": current_timestamp,
                    "model": body["model"],
                    "choices": [
                        {
                            "index": 0,
                            "delta": {
                                "content": f"\n\næ‰€æœ‰ {final_count} å¼ å›¾ç‰‡å¤„ç†å®Œæˆã€‚"
                            }
                        }
                    ],
                    "finish_reason": None
                }
                yield f"data: {json.dumps(completion_payload)}\n\n"
                
                # ç»“æŸå“åº”
                yield "data: [DONE]\n\n"
            
            return Response(
                stream_with_context(generate()),
                content_type="text/event-stream",
                headers={
                    "Cache-Control": "no-cache",
                    "X-Accel-Buffering": "no",  # ç¦ç”¨Nginxç¼“å†²
                    "Connection": "keep-alive"
                }
            )
        
        # éæµå¼å“åº” - åªè¿”å›ç¬¬ä¸€å¼ å›¾ç‰‡çš„ç»“æœ
        else:
            try:
                config = request_configs[0]
                logger.info(f"å‘é€è¯·æ±‚åˆ°: {config['url']}")
                logger.info(f"è¯·æ±‚å¤´: {config['headers']}")
                logger.info(f"è¯·æ±‚ä½“: {config['body']}")
                
                response = requests.post(config['url'], json=config['body'], headers=config['headers'])
                
                logger.info(f"APIå“åº”çŠ¶æ€ç : {response.status_code}")
                logger.info(f"APIå“åº”å†…å®¹: {response.text[:200]}...")
                
                # ç¡®ä¿å“åº”æ˜¯JSONæ ¼å¼
                try:
                    response_body = response.json()
                except json.JSONDecodeError as e:
                    logger.error(f"è§£æAPIå“åº”å¤±è´¥: {e}, å“åº”å†…å®¹: {response.text}")
                    return jsonify({"error": f"è§£æAPIå“åº”å¤±è´¥: {response.text[:100]}..."}), 500
                
                # æ£€æŸ¥å“åº”ä¸­æ˜¯å¦åŒ…å«å›¾åƒURL
                if isinstance(response_body, dict) and "images" in response_body and response_body["images"]:
                    # ç¡®ä¿imagesæ˜¯åˆ—è¡¨ä¸”åŒ…å«å­—å…¸å…ƒç´ 
                    if isinstance(response_body["images"], list) and len(response_body["images"]) > 0:
                        image_item = response_body["images"][0]
                        if isinstance(image_item, dict) and "url" in image_item:
                            image_url = image_item["url"]
                            logger.info(f"æ¥æ”¶åˆ°çš„ imageURL: {image_url}")
                            
                            # ç”ŸæˆçŸ­é“¾æ¥
                            short_url = generate_short_url(image_url)
                            
                            # ä¸Šä¼ åˆ°è“ç©ºå›¾åºŠ
                            lsky_url = upload_to_lsky_pro(image_url)
                            
                            # æ„å»ºå“åº”æ–‡æœ¬
                            escaped_prompt = json.dumps(safe_prompt)[1:-1]  # ä½¿ç”¨json.dumpså¤„ç†è½¬ä¹‰
                            
                            if lsky_url:
                                response_text = f"\n{{\n \"prompt\":\"{escaped_prompt}\",\n \"image_size\": \"{image_size}\",\n \"count\": {final_count}\n}}\n\nä¸‹è½½é“¾æ¥(é“¾æ¥æœ‰æ—¶æ•ˆæ€§ï¼ŒåŠæ—¶ä¸‹è½½ä¿å­˜)ï¼š{short_url}\n\nè“ç©ºå›¾åºŠé“¾æ¥(æ°¸ä¹…æœ‰æ•ˆ)ï¼š{lsky_url}\n\n![image1|{safe_prompt}]({lsky_url})"
                            else:
                                response_text = f"\n{{\n \"prompt\":\"{escaped_prompt}\",\n \"image_size\": \"{image_size}\",\n \"count\": {final_count}\n}}\n\nä¸‹è½½é“¾æ¥(é“¾æ¥æœ‰æ—¶æ•ˆæ€§ï¼ŒåŠæ—¶ä¸‹è½½ä¿å­˜)ï¼š{short_url}\n\n![image1|{safe_prompt}]({short_url})"
                            
                            return jsonify(send_response(body, response_text))
                        else:
                            logger.error(f"å›¾åƒé¡¹æ ¼å¼é”™è¯¯: {image_item}")
                            return jsonify({"error": "å›¾åƒæ ¼å¼é”™è¯¯"}), 500
                    else:
                        logger.error(f"å›¾åƒåˆ—è¡¨æ ¼å¼é”™è¯¯: {response_body['images']}")
                        return jsonify({"error": "å›¾åƒåˆ—è¡¨æ ¼å¼é”™è¯¯"}), 500
                else:
                    error_msg = "æœªçŸ¥é”™è¯¯"
                    if isinstance(response_body, dict) and "message" in response_body:
                        error_msg = str(response_body["message"])
                    logger.error(f"ç”»å›¾å¤±è´¥ï¼š{response_body}")
                    response_text = f"ç”Ÿæˆå›¾åƒå¤±è´¥: {error_msg}"
                    return jsonify(send_response(body, response_text))
            
            except Exception as e:
                logger.error(f"Error: {str(e)}")
                return jsonify({"error": f"Internal Server Error: {str(e)}"}), 500
    
    except Exception as e:
        logger.error(f"Request handling error: {str(e)}")
        return jsonify({"error": f"Internal Server Error: {str(e)}"}), 500

@app.route("/health", methods=["GET"])
def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return "OK", 200

if __name__ == "__main__":
    # è·å–ç«¯å£
    port = int(get_env("PORT", "7860"))
    
    # è·å–å›¾åƒæç¤ºæ¨¡å‹
    image_prompt_model = get_env("IMAGE_PROMPT_MODEL", "Qwen/Qwen2.5-7B-Instruct")
    
    # è·å–æœ€å¤§å›¾ç‰‡æ•°é‡
    max_images = get_env_int("MAX_IMAGES_PER_REQUEST", 4)
    
    # è·å–APIå¯†é’¥
    service_api_key = get_env("API_KEY", "")
    if service_api_key:
        logger.info("æœåŠ¡APIå¯†é’¥é‰´æƒå·²å¯ç”¨")
    else:
        logger.warning("æœåŠ¡APIå¯†é’¥é‰´æƒæœªå¯ç”¨ï¼ŒæœåŠ¡å¯èƒ½è¢«ä»»ä½•äººè®¿é—®")
    
    # æ£€æŸ¥å¤–éƒ¨APIå¯†é’¥
    external_api_keys = get_env("API_KEYS", "").split(",")
    if not external_api_keys or external_api_keys[0] == "":
        logger.error("æœªé…ç½®å¤–éƒ¨APIå¯†é’¥ï¼Œè¯·è®¾ç½®API_KEYSç¯å¢ƒå˜é‡")
    else:
        logger.info(f"å·²é…ç½® {len(external_api_keys)} ä¸ªå¤–éƒ¨APIå¯†é’¥")
    
    # æ£€æŸ¥çŸ­é“¾æ¥æœåŠ¡é…ç½®
    if get_env_bool("USE_SHORTLINK", False):
        logger.info("çŸ­é“¾æ¥æœåŠ¡å·²å¯ç”¨")
        if not get_env("SHORTLINK_BASE_URL") or not get_env("SHORTLINK_API_KEY"):
            logger.warning("çŸ­é“¾æ¥æœåŠ¡é…ç½®ä¸å®Œæ•´ï¼Œè¯·æ£€æŸ¥SHORTLINK_BASE_URLå’ŒSHORTLINK_API_KEYç¯å¢ƒå˜é‡")
    else:
        logger.info("çŸ­é“¾æ¥æœåŠ¡æœªå¯ç”¨")
    
    # æ£€æŸ¥è“ç©ºå›¾åºŠé…ç½®
    if get_env_bool("USE_LSKY_PRO", False):
        logger.info("è“ç©ºå›¾åºŠå·²å¯ç”¨")
        if not get_env("LSKY_PRO_URL") or not get_env("LSKY_PRO_TOKEN"):
            logger.warning("è“ç©ºå›¾åºŠé…ç½®ä¸å®Œæ•´ï¼Œè¯·æ£€æŸ¥LSKY_PRO_URLå’ŒLSKY_PRO_TOKENç¯å¢ƒå˜é‡")
    else:
        logger.info("è“ç©ºå›¾åºŠæœªå¯ç”¨")
    
    logger.info(f"æœåŠ¡é…ç½®: ç«¯å£={port}, æ¨¡å‹={image_prompt_model}, æœ€å¤§å›¾ç‰‡æ•°é‡={max_images}")
    logger.info(f"å…³é”®è¯è¿‡æ»¤: {get_env('BANNED_KEYWORDS', '')}")
    logger.info(f"æ”¯æŒçš„æ¨¡å‹æ•°é‡: {len(SUPPORTED_MODELS)}")
    
    # å¯åŠ¨æœåŠ¡
    app.run(host="0.0.0.0", port=port)

